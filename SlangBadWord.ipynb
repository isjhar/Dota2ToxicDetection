{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from profanity_check import predict, predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slangs\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Getting Abbreviation of words (Singkatan English) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "http = urllib3.PoolManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Abbr_dict={}\n",
    "#Load daftar slang word dari api noslang.com\n",
    "def getAbbr(alpha):\n",
    "    global Abbr_dict\n",
    "    r = http.request('GET','https://www.noslang.com/dictionary/'+alpha)\n",
    "    soup = BeautifulSoup(r.data,'html.parser')\n",
    "    \n",
    "    for i in soup.findAll('div',{'class':'dictionary-word'}): \n",
    "        abbr = i.find('abbr')['title']\n",
    "        Abbr_dict[i.find('span').text[:-2]] = abbr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkDict=[]\n",
    "\n",
    "for one in range(97,123):\n",
    "    linkDict.append(chr(one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in linkDict:\n",
    "    getAbbr(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hapus punctuation\n",
    "s = \"pro.\"\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "new_s = s.translate(table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'professional'"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#Test abbreviations\n",
    "Abbr_dict[new_s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocess Raw Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   match  slot                                               text\n0      2     0  yes dog. yeah . fast and furious. too fas. hah...\n1      2     2                          no idiot. we too pro. lol\n2      2     4                           HAHAH. COMMEND ME TY. EZ\n3      6     0  so ya mama likes dick ehh?. figures. ur not ev...\n4      6     1  reprot. SAD. fucking reported axe. WORST HOOK ...\n5      6     3                                                 gg\n6      6     4                                         axe is axe\n7      6     8                sorry nex. i killed u . almost . gg\n8      8     6  PUSH. not defending. dodger lc. swap commend t...\n9      9     3  what. jeje fAM. free farming ls. not coming in...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>match</th>\n      <th>slot</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0</td>\n      <td>yes dog. yeah . fast and furious. too fas. hah...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>no idiot. we too pro. lol</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>4</td>\n      <td>HAHAH. COMMEND ME TY. EZ</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>0</td>\n      <td>so ya mama likes dick ehh?. figures. ur not ev...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>1</td>\n      <td>reprot. SAD. fucking reported axe. WORST HOOK ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>3</td>\n      <td>gg</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>4</td>\n      <td>axe is axe</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6</td>\n      <td>8</td>\n      <td>sorry nex. i killed u . almost . gg</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>6</td>\n      <td>PUSH. not defending. dodger lc. swap commend t...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>3</td>\n      <td>what. jeje fAM. free farming ls. not coming in...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "data = pd.read_csv(\"dota2_chat_final.csv\", encoding=\"ISO-8859-1\", usecols=[\"match\", \"slot\", \"text\"])\n",
    "data = data.astype({\"match\": int, \"slot\": int, \"text\": str})\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessing Slang words and get the correct words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-48015484ee48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mall_words_no_punc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Hapus punctuation pada semua kata di dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "all_words = data.text.tolist()\n",
    "all_words_no_punc = []\n",
    "#Hapus punctuation pada semua kata di dataset\n",
    "for i in range(len(all_words)):\n",
    "    table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "    all_words_no_punc.append(all_words[i].lower().translate(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'all_words_no_punc' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-37c64b45c217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_words_no_punc_slangs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_words_no_punc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#print(all_words_no_punc[j])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_words_no_punc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_words_no_punc' is not defined"
     ]
    }
   ],
   "source": [
    "all_words_no_punc_slangs = []\n",
    "for j in range(len(all_words_no_punc)):\n",
    "    #print(all_words_no_punc[j])\n",
    "    line = all_words_no_punc[j].split()\n",
    "    for i in line:\n",
    "        #Pengecekan jika kata terdapat dalam daftar kata slangs, dan diganti dengan kata asli nya\n",
    "        if i in slangs.CONTRACTION_MAP:\n",
    "            line[line.index(i)] = slangs.CONTRACTION_MAP[i]\n",
    "        #Pengecekan jika kata tidak terdapat dalam daftar kata slangs, cek langsung dengan abbreviation list\n",
    "        elif i in Abbr_dict:\n",
    "            line[line.index(i)] = Abbr_dict[i]\n",
    "    all_words_no_punc_slangs.append(' '.join(line).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-79d24d139d38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_words_no_punc_slangs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(all_words_no_punc_slangs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Bad and Insult Words Classification</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#Bad or Insult words classification dari kata setelah preprocessing dengan profanity checker\n",
    "for i in range(len(all_words_no_punc_slangs)):\n",
    "    print(all_words_no_punc_slangs[i][0:30]+\"...\", predict_prob([all_words_no_punc_slangs[i]])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}