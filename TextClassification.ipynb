{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<title>Toxic Player Detection Dota 2</title>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\isjha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pickle\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_SIZE = 100\n",
    "BATCH_SIZE = 64\n",
    "PAD_WORD = \"__PAD__\"\n",
    "WORD_EMBEDDING_FILE = 'word_embedding.csv'\n",
    "TOKENIZER_FILE = 'tokenizer.pickle'\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocess Raw Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>slot</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>ладно гг</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>изи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>од</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>ебаный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>мусор на войде</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>мусор</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>на войде</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>репорт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>twitch.tv/rage_channel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match  slot                    text\n",
       "0      0     9               ладно гг \n",
       "1      0     9                     изи\n",
       "2      0     9                      од\n",
       "3      0     9                  ебаный\n",
       "4      0     9          мусор на войде\n",
       "5      0     9                  мусор \n",
       "6      0     9                на войде\n",
       "7      0     9                  репорт\n",
       "8      0     9                    100%\n",
       "9      1     0  twitch.tv/rage_channel"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dota2_chat_messages.csv\", encoding=\"utf_8\", usecols=[\"match\", \"slot\", \"text\"])\n",
    "data = data.astype({\"match\": int, \"slot\": int, \"text\": str})\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "match  slot\n",
       "0      9       ладно гг . изи. од. ебаный. мусор на войде. му...\n",
       "1      0       twitch.tv/rage_channel. https://www.twitch.tv/...\n",
       "       4       где даша?. даша домой. долбоеб сука на дизрапторе\n",
       "       6       даун с 1 тычки забашил . шок . стример харду с...\n",
       "       7                                   2 даша подряд . баша \n",
       "       8                                                     )))\n",
       "2      0       yes dog. yeah . fast and furious. too fas. hah...\n",
       "       2                               no idiot. we too pro. lol\n",
       "       4                                HAHAH. COMMEND ME TY. EZ\n",
       "       6                                              carry. lul\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.groupby(['match', 'slot'])['text'].apply('. '.join)\n",
    "data.reset_index()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>slot</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>ладно гг . изи. од. ебаный. мусор на войде. му...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>twitch.tv/rage_channel. https://www.twitch.tv/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>где даша?. даша домой. долбоеб сука на дизрапторе</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>даун с 1 тычки забашил . шок . стример харду с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2 даша подряд . баша</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>)))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes dog. yeah . fast and furious. too fas. hah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>no idiot. we too pro. lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>HAHAH. COMMEND ME TY. EZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>carry. lul</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match  slot                                               text\n",
       "0      0     9  ладно гг . изи. од. ебаный. мусор на войде. му...\n",
       "1      1     0  twitch.tv/rage_channel. https://www.twitch.tv/...\n",
       "2      1     4  где даша?. даша домой. долбоеб сука на дизрапторе\n",
       "3      1     6  даун с 1 тычки забашил . шок . стример харду с...\n",
       "4      1     7                              2 даша подряд . баша \n",
       "5      1     8                                                )))\n",
       "6      2     0  yes dog. yeah . fast and furious. too fas. hah...\n",
       "7      2     2                          no idiot. we too pro. lol\n",
       "8      2     4                           HAHAH. COMMEND ME TY. EZ\n",
       "9      2     6                                         carry. lul"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reset_index()\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"dota2_chat_joined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>slot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>4.747547e+06</td>\n",
       "      <td>4.747547e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>4.999057e+05</td>\n",
       "      <td>4.493503e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.887862e+05</td>\n",
       "      <td>2.873926e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.497860e+05</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>4.999710e+05</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7.500870e+05</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>9.999990e+05</td>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              match          slot\n",
       "count  4.747547e+06  4.747547e+06\n",
       "mean   4.999057e+05  4.493503e+00\n",
       "std    2.887862e+05  2.873926e+00\n",
       "min    0.000000e+00  0.000000e+00\n",
       "25%    2.497860e+05  2.000000e+00\n",
       "50%    4.999710e+05  5.000000e+00\n",
       "75%    7.500870e+05  7.000000e+00\n",
       "max    9.999990e+05  9.000000e+00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classification</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load word embedding\n",
    "word_embedding = np.loadtxt(WORD_EMBEDDING_FILE, delimiter=',')\n",
    "#load tokenizer \n",
    "with open(TOKENIZER_FILE, 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    319\n",
       "1    164\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dota2_chat_final.csv\", encoding=\"latin_1\", usecols=[\"category\", \"match\", \"slot\", \"text\"])\n",
    "data[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>match</th>\n",
       "      <th>slot</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>yes dog. yeah . fast and furious. too fas. hah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>no idiot. we too pro. lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>HAHAH. COMMEND ME TY. EZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>so ya mama likes dick ehh?. figures. ur not ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>reprot. SAD. fucking reported axe. WORST HOOK ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category  match  slot                                               text\n",
       "0         0      2     0  yes dog. yeah . fast and furious. too fas. hah...\n",
       "1         0      2     2                          no idiot. we too pro. lol\n",
       "2         1      2     4                           HAHAH. COMMEND ME TY. EZ\n",
       "3         1      6     0  so ya mama likes dick ehh?. figures. ur not ev...\n",
       "4         1      6     1  reprot. SAD. fucking reported axe. WORST HOOK ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = data.drop(columns=['category', 'match', 'slot']).to_numpy().flatten()\n",
    "y_raw = data.drop(columns=['text', 'match', 'slot']).to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_match(X1, X2):\n",
    "    for i in range(len(X1)):\n",
    "        arr1 = X1[i]\n",
    "        arr2 = X2[i]\n",
    "        if(len(arr1) != len(arr2)):\n",
    "            print(i)\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(X_raw)\n",
    "y = to_categorical(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[145, 59, 163, 117, 14, 999, 130, 1000, 27, 71]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k at didnt plz a paid an while end hahaha']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[231, 66, 174, 114, 13, 771, 175, 772, 19, 92]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = []\n",
    "[words.extend(sentence) for sentence in X]\n",
    "freqdist = nltk.FreqDist(words)\n",
    "x_plot = [freqdist[word] for word in words]\n",
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(x_plot, 50, density=1, facecolor='g', alpha=0.75)\n",
    "\n",
    "\n",
    "plt.xlabel('FreqDist')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Histogram of IQ')\n",
    "plt.axis([min(x_plot)-10, max(x_plot)+ 10, 0, 0.1])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded = pad_sequences(X, maxlen=SEQUENCE_LENGTH, padding='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Validation Test</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2365, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LSTM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 100)          236500    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 354,006\n",
      "Trainable params: 117,506\n",
      "Non-trainable params: 236,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_val = Sequential()\n",
    "model_val.add(Embedding(\n",
    "    input_dim=len(tokenizer.word_index)+1, \n",
    "    output_dim=EMBEDDING_SIZE, \n",
    "    input_length=SEQUENCE_LENGTH, \n",
    "    weights=[word_embedding],\n",
    "    trainable=False))\n",
    "model_val.add(LSTM(128, recurrent_dropout=0.2))\n",
    "model_val.add(Dropout(0.3))\n",
    "model_val.add(Dense(2, activation=\"softmax\"))\n",
    "# compile as rmsprop optimizer\n",
    "# aswell as with recall metric\n",
    "model_val.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", \n",
    "      metrics=[\"accuracy\", f1_m])\n",
    "model_val.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples, validate on 131 samples\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 3s 10ms/sample - loss: 0.8714 - accuracy: 0.6634 - f1_m: 0.6195 - val_loss: 0.5846 - val_accuracy: 0.6870 - val_f1_m: 0.6806\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5412 - accuracy: 0.7426 - f1_m: 0.7461 - val_loss: 0.5415 - val_accuracy: 0.7099 - val_f1_m: 0.8021\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5324 - accuracy: 0.7327 - f1_m: 0.7356 - val_loss: 0.4948 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5289 - accuracy: 0.7327 - f1_m: 0.7311 - val_loss: 0.5005 - val_accuracy: 0.7557 - val_f1_m: 0.8333\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5340 - accuracy: 0.7261 - f1_m: 0.7271 - val_loss: 0.5557 - val_accuracy: 0.7023 - val_f1_m: 0.6910\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5382 - accuracy: 0.7360 - f1_m: 0.7364 - val_loss: 0.5405 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5229 - accuracy: 0.7426 - f1_m: 0.7449 - val_loss: 0.5179 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5882 - accuracy: 0.6766 - f1_m: 0.6768 - val_loss: 0.5711 - val_accuracy: 0.6870 - val_f1_m: 0.6806\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5464 - accuracy: 0.7030 - f1_m: 0.7007 - val_loss: 0.5157 - val_accuracy: 0.7099 - val_f1_m: 0.8021\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5442 - accuracy: 0.6931 - f1_m: 0.6981 - val_loss: 0.5433 - val_accuracy: 0.7023 - val_f1_m: 0.6910\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5413 - accuracy: 0.7261 - f1_m: 0.7237 - val_loss: 0.5103 - val_accuracy: 0.7099 - val_f1_m: 0.8021\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5281 - accuracy: 0.7558 - f1_m: 0.7541 - val_loss: 0.5246 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5369 - accuracy: 0.7360 - f1_m: 0.7342 - val_loss: 0.5126 - val_accuracy: 0.7328 - val_f1_m: 0.8177\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5612 - accuracy: 0.7030 - f1_m: 0.7029 - val_loss: 0.5763 - val_accuracy: 0.6870 - val_f1_m: 0.6806\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5422 - accuracy: 0.7096 - f1_m: 0.7103 - val_loss: 0.5063 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5245 - accuracy: 0.7393 - f1_m: 0.7407 - val_loss: 0.4990 - val_accuracy: 0.7099 - val_f1_m: 0.8021\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5147 - accuracy: 0.7096 - f1_m: 0.7126 - val_loss: 0.5352 - val_accuracy: 0.7023 - val_f1_m: 0.6910\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5241 - accuracy: 0.7228 - f1_m: 0.7239 - val_loss: 0.5700 - val_accuracy: 0.7023 - val_f1_m: 0.6910\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5611 - accuracy: 0.7228 - f1_m: 0.7273 - val_loss: 0.5086 - val_accuracy: 0.7099 - val_f1_m: 0.8021\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5305 - accuracy: 0.7129 - f1_m: 0.7134 - val_loss: 0.5437 - val_accuracy: 0.7023 - val_f1_m: 0.6910\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5627 - accuracy: 0.7294 - f1_m: 0.7245 - val_loss: 0.5370 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5346 - accuracy: 0.7162 - f1_m: 0.7154 - val_loss: 0.4971 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5297 - accuracy: 0.7129 - f1_m: 0.7100 - val_loss: 0.4965 - val_accuracy: 0.7099 - val_f1_m: 0.8021\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5019 - accuracy: 0.7624 - f1_m: 0.7614 - val_loss: 0.4864 - val_accuracy: 0.8092 - val_f1_m: 0.8698\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5515 - accuracy: 0.7195 - f1_m: 0.7265 - val_loss: 0.4932 - val_accuracy: 0.7481 - val_f1_m: 0.8281\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5117 - accuracy: 0.7129 - f1_m: 0.7146 - val_loss: 0.5270 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5256 - accuracy: 0.7492 - f1_m: 0.7467 - val_loss: 0.5366 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5073 - accuracy: 0.7492 - f1_m: 0.7535 - val_loss: 0.5023 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5574 - accuracy: 0.6964 - f1_m: 0.6967 - val_loss: 0.5171 - val_accuracy: 0.7099 - val_f1_m: 0.8021\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5085 - accuracy: 0.7393 - f1_m: 0.7384 - val_loss: 0.5093 - val_accuracy: 0.7099 - val_f1_m: 0.8021\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5001 - accuracy: 0.7657 - f1_m: 0.7668 - val_loss: 0.4973 - val_accuracy: 0.7099 - val_f1_m: 0.8021\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5310 - accuracy: 0.7459 - f1_m: 0.7503 - val_loss: 0.4999 - val_accuracy: 0.7099 - val_f1_m: 0.8021\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5112 - accuracy: 0.7624 - f1_m: 0.7626 - val_loss: 0.5048 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5257 - accuracy: 0.7591 - f1_m: 0.7628 - val_loss: 0.5046 - val_accuracy: 0.7099 - val_f1_m: 0.8021\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5181 - accuracy: 0.7459 - f1_m: 0.7515 - val_loss: 0.5291 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4991 - accuracy: 0.7558 - f1_m: 0.7541 - val_loss: 0.5313 - val_accuracy: 0.7099 - val_f1_m: 0.8021\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5200 - accuracy: 0.7624 - f1_m: 0.7637 - val_loss: 0.5083 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4936 - accuracy: 0.7525 - f1_m: 0.7543 - val_loss: 0.5017 - val_accuracy: 0.7099 - val_f1_m: 0.8021\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5294 - accuracy: 0.7096 - f1_m: 0.7126 - val_loss: 0.5473 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5285 - accuracy: 0.7327 - f1_m: 0.7356 - val_loss: 0.4833 - val_accuracy: 0.7786 - val_f1_m: 0.8490\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5192 - accuracy: 0.7657 - f1_m: 0.7668 - val_loss: 0.5013 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5124 - accuracy: 0.7492 - f1_m: 0.7467 - val_loss: 0.4756 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4991 - accuracy: 0.7591 - f1_m: 0.7583 - val_loss: 0.5023 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4980 - accuracy: 0.7756 - f1_m: 0.7739 - val_loss: 0.4932 - val_accuracy: 0.8244 - val_f1_m: 0.8802\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5289 - accuracy: 0.7426 - f1_m: 0.7438 - val_loss: 0.4766 - val_accuracy: 0.8092 - val_f1_m: 0.8698\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5152 - accuracy: 0.7591 - f1_m: 0.7617 - val_loss: 0.4873 - val_accuracy: 0.7634 - val_f1_m: 0.8385\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5246 - accuracy: 0.7195 - f1_m: 0.7231 - val_loss: 0.4823 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4937 - accuracy: 0.7822 - f1_m: 0.7779 - val_loss: 0.4821 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5197 - accuracy: 0.7261 - f1_m: 0.7191 - val_loss: 0.4905 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5154 - accuracy: 0.7690 - f1_m: 0.7699 - val_loss: 0.4911 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4977 - accuracy: 0.7723 - f1_m: 0.7719 - val_loss: 0.4986 - val_accuracy: 0.7481 - val_f1_m: 0.8281\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5048 - accuracy: 0.7723 - f1_m: 0.7776 - val_loss: 0.5124 - val_accuracy: 0.7634 - val_f1_m: 0.8385\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4948 - accuracy: 0.7558 - f1_m: 0.7529 - val_loss: 0.4782 - val_accuracy: 0.7786 - val_f1_m: 0.8490\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5253 - accuracy: 0.7723 - f1_m: 0.7663 - val_loss: 0.5018 - val_accuracy: 0.7634 - val_f1_m: 0.8385\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5206 - accuracy: 0.7558 - f1_m: 0.7563 - val_loss: 0.4870 - val_accuracy: 0.7481 - val_f1_m: 0.8281\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4862 - accuracy: 0.7789 - f1_m: 0.7782 - val_loss: 0.4776 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4840 - accuracy: 0.7756 - f1_m: 0.7739 - val_loss: 0.4716 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5002 - accuracy: 0.7789 - f1_m: 0.7805 - val_loss: 0.4717 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4934 - accuracy: 0.7690 - f1_m: 0.7699 - val_loss: 0.4814 - val_accuracy: 0.7634 - val_f1_m: 0.8385\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5049 - accuracy: 0.7624 - f1_m: 0.7648 - val_loss: 0.4712 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4815 - accuracy: 0.7756 - f1_m: 0.7728 - val_loss: 0.4783 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5203 - accuracy: 0.7591 - f1_m: 0.7572 - val_loss: 0.5036 - val_accuracy: 0.7481 - val_f1_m: 0.8281\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4893 - accuracy: 0.7756 - f1_m: 0.7762 - val_loss: 0.4882 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5145 - accuracy: 0.7294 - f1_m: 0.7347 - val_loss: 0.5036 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5259 - accuracy: 0.7591 - f1_m: 0.7583 - val_loss: 0.4801 - val_accuracy: 0.7634 - val_f1_m: 0.8385\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4846 - accuracy: 0.7756 - f1_m: 0.7717 - val_loss: 0.4707 - val_accuracy: 0.8321 - val_f1_m: 0.8854\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5009 - accuracy: 0.7690 - f1_m: 0.7666 - val_loss: 0.4745 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4868 - accuracy: 0.7591 - f1_m: 0.7527 - val_loss: 0.5093 - val_accuracy: 0.7481 - val_f1_m: 0.8281\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5022 - accuracy: 0.7558 - f1_m: 0.7495 - val_loss: 0.4823 - val_accuracy: 0.7481 - val_f1_m: 0.8281\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4867 - accuracy: 0.7657 - f1_m: 0.7612 - val_loss: 0.4932 - val_accuracy: 0.7786 - val_f1_m: 0.8490\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4822 - accuracy: 0.7855 - f1_m: 0.7833 - val_loss: 0.4876 - val_accuracy: 0.7405 - val_f1_m: 0.8229\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4890 - accuracy: 0.7690 - f1_m: 0.7722 - val_loss: 0.5636 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4950 - accuracy: 0.7525 - f1_m: 0.7509 - val_loss: 0.4917 - val_accuracy: 0.7557 - val_f1_m: 0.8333\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4781 - accuracy: 0.7624 - f1_m: 0.7637 - val_loss: 0.4820 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5102 - accuracy: 0.7591 - f1_m: 0.7572 - val_loss: 0.5025 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4928 - accuracy: 0.7525 - f1_m: 0.7521 - val_loss: 0.4871 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5138 - accuracy: 0.7591 - f1_m: 0.7583 - val_loss: 0.4732 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5098 - accuracy: 0.7591 - f1_m: 0.7628 - val_loss: 0.4729 - val_accuracy: 0.8092 - val_f1_m: 0.8698\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5028 - accuracy: 0.7756 - f1_m: 0.7694 - val_loss: 0.5037 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5031 - accuracy: 0.7624 - f1_m: 0.7614 - val_loss: 0.4878 - val_accuracy: 0.7405 - val_f1_m: 0.8229\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5018 - accuracy: 0.7492 - f1_m: 0.7512 - val_loss: 0.4990 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4927 - accuracy: 0.7756 - f1_m: 0.7739 - val_loss: 0.4709 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4947 - accuracy: 0.7690 - f1_m: 0.7699 - val_loss: 0.4765 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4953 - accuracy: 0.7822 - f1_m: 0.7802 - val_loss: 0.4858 - val_accuracy: 0.7481 - val_f1_m: 0.8281\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4772 - accuracy: 0.7756 - f1_m: 0.7717 - val_loss: 0.4692 - val_accuracy: 0.8244 - val_f1_m: 0.8802\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5028 - accuracy: 0.7657 - f1_m: 0.7680 - val_loss: 0.4754 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4998 - accuracy: 0.7657 - f1_m: 0.7623 - val_loss: 0.4785 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5001 - accuracy: 0.7888 - f1_m: 0.7887 - val_loss: 0.4913 - val_accuracy: 0.7328 - val_f1_m: 0.8177\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5026 - accuracy: 0.7789 - f1_m: 0.7838 - val_loss: 0.4753 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4792 - accuracy: 0.7723 - f1_m: 0.7708 - val_loss: 0.4888 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5126 - accuracy: 0.7558 - f1_m: 0.7552 - val_loss: 0.4803 - val_accuracy: 0.7786 - val_f1_m: 0.8490\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5030 - accuracy: 0.7492 - f1_m: 0.7501 - val_loss: 0.4962 - val_accuracy: 0.7176 - val_f1_m: 0.8073\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4999 - accuracy: 0.7921 - f1_m: 0.7918 - val_loss: 0.4797 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5078 - accuracy: 0.7525 - f1_m: 0.7475 - val_loss: 0.4888 - val_accuracy: 0.8092 - val_f1_m: 0.8698\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4869 - accuracy: 0.7558 - f1_m: 0.7529 - val_loss: 0.4781 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5035 - accuracy: 0.7789 - f1_m: 0.7748 - val_loss: 0.5157 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.5090 - accuracy: 0.7426 - f1_m: 0.7461 - val_loss: 0.4956 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4958 - accuracy: 0.7756 - f1_m: 0.7773 - val_loss: 0.4833 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4926 - accuracy: 0.7756 - f1_m: 0.7739 - val_loss: 0.4999 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 1s 4ms/sample - loss: 0.4969 - accuracy: 0.7426 - f1_m: 0.7427 - val_loss: 0.4790 - val_accuracy: 0.7710 - val_f1_m: 0.8438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ebbd98588>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_val.fit(X_train, y_train, epochs=100, batch_size=64, shuffle=True, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.4738161335892392 , accuracy:  0.7718894 , f1 score:  0.7703372\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1_score = model_val.evaluate(X_train, y_train, verbose=0)\n",
    "print('loss: ', loss, ', accuracy: ', accuracy, ', f1 score: ', f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bidirectional LSTM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 100)          236500    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 256)               234496    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 471,510\n",
      "Trainable params: 235,010\n",
      "Non-trainable params: 236,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2_val = Sequential()\n",
    "model_2_val.add(Embedding(\n",
    "    input_dim=len(tokenizer.word_index)+1, \n",
    "    output_dim=EMBEDDING_SIZE, \n",
    "    input_length=SEQUENCE_LENGTH, \n",
    "    weights=[word_embedding],\n",
    "    trainable=False))\n",
    "model_2_val.add(Bidirectional(LSTM(128)))\n",
    "model_2_val.add(Dropout(0.3))\n",
    "model_2_val.add(Dense(2, activation=\"softmax\"))\n",
    "# compile as rmsprop optimizer\n",
    "# aswell as with recall metric\n",
    "model_2_val.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", \n",
    "      metrics=[\"accuracy\", f1_m])\n",
    "model_2_val.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples, validate on 131 samples\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 9s 31ms/sample - loss: 0.6701 - accuracy: 0.6271 - f1_m: 0.6277 - val_loss: 0.6299 - val_accuracy: 0.6947 - val_f1_m: 0.6858\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.6050 - accuracy: 0.7096 - f1_m: 0.7114 - val_loss: 0.5796 - val_accuracy: 0.6870 - val_f1_m: 0.6806\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5704 - accuracy: 0.7261 - f1_m: 0.7259 - val_loss: 0.5286 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5460 - accuracy: 0.7690 - f1_m: 0.7666 - val_loss: 0.5059 - val_accuracy: 0.8092 - val_f1_m: 0.8698\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5237 - accuracy: 0.7558 - f1_m: 0.7563 - val_loss: 0.5029 - val_accuracy: 0.7786 - val_f1_m: 0.8490\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5151 - accuracy: 0.7492 - f1_m: 0.7557 - val_loss: 0.5240 - val_accuracy: 0.7557 - val_f1_m: 0.8333\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5179 - accuracy: 0.7690 - f1_m: 0.7699 - val_loss: 0.5047 - val_accuracy: 0.7786 - val_f1_m: 0.8490\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5034 - accuracy: 0.7690 - f1_m: 0.7733 - val_loss: 0.4834 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4951 - accuracy: 0.7822 - f1_m: 0.7847 - val_loss: 0.4823 - val_accuracy: 0.8092 - val_f1_m: 0.8698\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4914 - accuracy: 0.7789 - f1_m: 0.7782 - val_loss: 0.5146 - val_accuracy: 0.7786 - val_f1_m: 0.8490\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5076 - accuracy: 0.7426 - f1_m: 0.7427 - val_loss: 0.4932 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5417 - accuracy: 0.7756 - f1_m: 0.7739 - val_loss: 0.4982 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5073 - accuracy: 0.7558 - f1_m: 0.7574 - val_loss: 0.5207 - val_accuracy: 0.7405 - val_f1_m: 0.8229\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5017 - accuracy: 0.7558 - f1_m: 0.7574 - val_loss: 0.4835 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4931 - accuracy: 0.7888 - f1_m: 0.7887 - val_loss: 0.5017 - val_accuracy: 0.7786 - val_f1_m: 0.8490\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4969 - accuracy: 0.7789 - f1_m: 0.7771 - val_loss: 0.4917 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4819 - accuracy: 0.7591 - f1_m: 0.7538 - val_loss: 0.4819 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4851 - accuracy: 0.7888 - f1_m: 0.7853 - val_loss: 0.4825 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4801 - accuracy: 0.7855 - f1_m: 0.7878 - val_loss: 0.4777 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4930 - accuracy: 0.7690 - f1_m: 0.7654 - val_loss: 0.5186 - val_accuracy: 0.7557 - val_f1_m: 0.8333\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4912 - accuracy: 0.7789 - f1_m: 0.7838 - val_loss: 0.4991 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4883 - accuracy: 0.7723 - f1_m: 0.7731 - val_loss: 0.4724 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5080 - accuracy: 0.7591 - f1_m: 0.7561 - val_loss: 0.5212 - val_accuracy: 0.6718 - val_f1_m: 0.6701\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4957 - accuracy: 0.7657 - f1_m: 0.7702 - val_loss: 0.4740 - val_accuracy: 0.8092 - val_f1_m: 0.8698\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4795 - accuracy: 0.8020 - f1_m: 0.8080 - val_loss: 0.4734 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4993 - accuracy: 0.7855 - f1_m: 0.7833 - val_loss: 0.5077 - val_accuracy: 0.7252 - val_f1_m: 0.8125\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4893 - accuracy: 0.7591 - f1_m: 0.7606 - val_loss: 0.4748 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4999 - accuracy: 0.7756 - f1_m: 0.7762 - val_loss: 0.4784 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4948 - accuracy: 0.7690 - f1_m: 0.7654 - val_loss: 0.4769 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4786 - accuracy: 0.7855 - f1_m: 0.7844 - val_loss: 0.4729 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4864 - accuracy: 0.7888 - f1_m: 0.7864 - val_loss: 0.4828 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4840 - accuracy: 0.7723 - f1_m: 0.7697 - val_loss: 0.4745 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4789 - accuracy: 0.7855 - f1_m: 0.7856 - val_loss: 0.4742 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4928 - accuracy: 0.7789 - f1_m: 0.7759 - val_loss: 0.4711 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4894 - accuracy: 0.7789 - f1_m: 0.7771 - val_loss: 0.4807 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4985 - accuracy: 0.7756 - f1_m: 0.7739 - val_loss: 0.4884 - val_accuracy: 0.7634 - val_f1_m: 0.8385\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4840 - accuracy: 0.7591 - f1_m: 0.7561 - val_loss: 0.4770 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4898 - accuracy: 0.7723 - f1_m: 0.7686 - val_loss: 0.4834 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4957 - accuracy: 0.7855 - f1_m: 0.7890 - val_loss: 0.4699 - val_accuracy: 0.8092 - val_f1_m: 0.8698\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5017 - accuracy: 0.7525 - f1_m: 0.7543 - val_loss: 0.4664 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4892 - accuracy: 0.7921 - f1_m: 0.7963 - val_loss: 0.4642 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5024 - accuracy: 0.7459 - f1_m: 0.7436 - val_loss: 0.4736 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4798 - accuracy: 0.7789 - f1_m: 0.7771 - val_loss: 0.4747 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4954 - accuracy: 0.7657 - f1_m: 0.7634 - val_loss: 0.4733 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4819 - accuracy: 0.7756 - f1_m: 0.7762 - val_loss: 0.4643 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4761 - accuracy: 0.7690 - f1_m: 0.7733 - val_loss: 0.4779 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4747 - accuracy: 0.7822 - f1_m: 0.7824 - val_loss: 0.4671 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5046 - accuracy: 0.7756 - f1_m: 0.7762 - val_loss: 0.4761 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4867 - accuracy: 0.7657 - f1_m: 0.7657 - val_loss: 0.4693 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4893 - accuracy: 0.7822 - f1_m: 0.7791 - val_loss: 0.5156 - val_accuracy: 0.7481 - val_f1_m: 0.8281\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4807 - accuracy: 0.7723 - f1_m: 0.7719 - val_loss: 0.4711 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4774 - accuracy: 0.7789 - f1_m: 0.7816 - val_loss: 0.4846 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4887 - accuracy: 0.7855 - f1_m: 0.7811 - val_loss: 0.4764 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4781 - accuracy: 0.7822 - f1_m: 0.7813 - val_loss: 0.4913 - val_accuracy: 0.7634 - val_f1_m: 0.8385\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4956 - accuracy: 0.7723 - f1_m: 0.7753 - val_loss: 0.4808 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4796 - accuracy: 0.7822 - f1_m: 0.7824 - val_loss: 0.4692 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4767 - accuracy: 0.7822 - f1_m: 0.7813 - val_loss: 0.5050 - val_accuracy: 0.7405 - val_f1_m: 0.8229\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4808 - accuracy: 0.7657 - f1_m: 0.7702 - val_loss: 0.4910 - val_accuracy: 0.7786 - val_f1_m: 0.8490\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4969 - accuracy: 0.7690 - f1_m: 0.7666 - val_loss: 0.4695 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4798 - accuracy: 0.7954 - f1_m: 0.7972 - val_loss: 0.4739 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4704 - accuracy: 0.7822 - f1_m: 0.7836 - val_loss: 0.4692 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4975 - accuracy: 0.7624 - f1_m: 0.7580 - val_loss: 0.4744 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4768 - accuracy: 0.7822 - f1_m: 0.7813 - val_loss: 0.4721 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4856 - accuracy: 0.7657 - f1_m: 0.7623 - val_loss: 0.4986 - val_accuracy: 0.7481 - val_f1_m: 0.8281\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4758 - accuracy: 0.7723 - f1_m: 0.7742 - val_loss: 0.4680 - val_accuracy: 0.8092 - val_f1_m: 0.8698\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4728 - accuracy: 0.7789 - f1_m: 0.7782 - val_loss: 0.4901 - val_accuracy: 0.7786 - val_f1_m: 0.8490\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4851 - accuracy: 0.7690 - f1_m: 0.7654 - val_loss: 0.4718 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4814 - accuracy: 0.7789 - f1_m: 0.7782 - val_loss: 0.4690 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4715 - accuracy: 0.7888 - f1_m: 0.7864 - val_loss: 0.4670 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4757 - accuracy: 0.7888 - f1_m: 0.7898 - val_loss: 0.4648 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4709 - accuracy: 0.7723 - f1_m: 0.7686 - val_loss: 0.4876 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4934 - accuracy: 0.8020 - f1_m: 0.7967 - val_loss: 0.4649 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4783 - accuracy: 0.7921 - f1_m: 0.7896 - val_loss: 0.4782 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4862 - accuracy: 0.7789 - f1_m: 0.7816 - val_loss: 0.4613 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4859 - accuracy: 0.7756 - f1_m: 0.7672 - val_loss: 0.4739 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4795 - accuracy: 0.7723 - f1_m: 0.7663 - val_loss: 0.4735 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4773 - accuracy: 0.7855 - f1_m: 0.7822 - val_loss: 0.4683 - val_accuracy: 0.8092 - val_f1_m: 0.8698\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4786 - accuracy: 0.7789 - f1_m: 0.7793 - val_loss: 0.4619 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4802 - accuracy: 0.7855 - f1_m: 0.7833 - val_loss: 0.4678 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5020 - accuracy: 0.7756 - f1_m: 0.7705 - val_loss: 0.4706 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4822 - accuracy: 0.7789 - f1_m: 0.7793 - val_loss: 0.4676 - val_accuracy: 0.8092 - val_f1_m: 0.8698\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4713 - accuracy: 0.7789 - f1_m: 0.7793 - val_loss: 0.4646 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4815 - accuracy: 0.7756 - f1_m: 0.7728 - val_loss: 0.4685 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4681 - accuracy: 0.7690 - f1_m: 0.7654 - val_loss: 0.4694 - val_accuracy: 0.7863 - val_f1_m: 0.8542\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4829 - accuracy: 0.7624 - f1_m: 0.7603 - val_loss: 0.4920 - val_accuracy: 0.7557 - val_f1_m: 0.8333\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4814 - accuracy: 0.7591 - f1_m: 0.7628 - val_loss: 0.4667 - val_accuracy: 0.8168 - val_f1_m: 0.8750\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4844 - accuracy: 0.7723 - f1_m: 0.7753 - val_loss: 0.4650 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4699 - accuracy: 0.7822 - f1_m: 0.7836 - val_loss: 0.4827 - val_accuracy: 0.7786 - val_f1_m: 0.8490\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4745 - accuracy: 0.7822 - f1_m: 0.7847 - val_loss: 0.4642 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4671 - accuracy: 0.7921 - f1_m: 0.7918 - val_loss: 0.4749 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4841 - accuracy: 0.7690 - f1_m: 0.7699 - val_loss: 0.4823 - val_accuracy: 0.7786 - val_f1_m: 0.8490\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4688 - accuracy: 0.7888 - f1_m: 0.7864 - val_loss: 0.4640 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4776 - accuracy: 0.7756 - f1_m: 0.7739 - val_loss: 0.4686 - val_accuracy: 0.8092 - val_f1_m: 0.8698\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4787 - accuracy: 0.7789 - f1_m: 0.7805 - val_loss: 0.4621 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4622 - accuracy: 0.7855 - f1_m: 0.7856 - val_loss: 0.4717 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4783 - accuracy: 0.7822 - f1_m: 0.7847 - val_loss: 0.4648 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4668 - accuracy: 0.7954 - f1_m: 0.7949 - val_loss: 0.4590 - val_accuracy: 0.8092 - val_f1_m: 0.8698\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4768 - accuracy: 0.7822 - f1_m: 0.7802 - val_loss: 0.4676 - val_accuracy: 0.8015 - val_f1_m: 0.8646\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.4767 - accuracy: 0.7822 - f1_m: 0.7791 - val_loss: 0.4591 - val_accuracy: 0.7939 - val_f1_m: 0.8594\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 1s 3ms/sample - loss: 0.5694 - accuracy: 0.7261 - f1_m: 0.7033 - val_loss: 0.4815 - val_accuracy: 0.7786 - val_f1_m: 0.8490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ec93ba408>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_val.fit(X_train, y_train, epochs=100, batch_size=64, shuffle=True, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.4780027109631745 , accuracy:  0.78341013 , f1 score:  0.78497016\n"
     ]
    }
   ],
   "source": [
    "loss_2, accuracy_2, f1_score_2 = model_2_val.evaluate(X_train, y_train, verbose=0)\n",
    "print('loss: ', loss_2, ', accuracy: ', accuracy_2, ', f1 score: ', f1_score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
